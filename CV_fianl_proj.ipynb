{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Lets get our dataset from google drive"
      ],
      "metadata": {
        "id": "tvkkydFztArT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIekOLQvTNMu"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/Data/CV_proj\""
      ],
      "metadata": {
        "id": "4SMErOSLTO9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/drive/MyDrive/Data/CV_proj/data.zip\n",
        "#/content/drive/MyDrive/Data/Trays"
      ],
      "metadata": {
        "id": "-amzan71TW5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "import PIL\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torchvision\n",
        "# from torch_snippets import Report\n",
        "import os\n",
        "import time\n",
        "import xml.etree.ElementTree as ET\n",
        "# Connect to the GPU if one exists.\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "\n",
        "from torchvision.ops.boxes import nms"
      ],
      "metadata": {
        "id": "0f-FHY9eTdVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install opendatasets\n",
        "# !pip install pandas"
      ],
      "metadata": {
        "id": "f49RzYs4UKYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Now we need to convert our data to dataframe"
      ],
      "metadata": {
        "id": "z76f3lvGtJYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_xml_to_dict(xml_path):\n",
        "    # Decode the .xml file\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "    # Return the image size, object label and bounding box\n",
        "    # coordinates together with the filename as a dict.\n",
        "    names = []\n",
        "    for tag in root.findall('object/name'):\n",
        "        names.append(tag.text)\n",
        "\n",
        "    x_mins = []\n",
        "    for tag in root.findall('object/bndbox/xmin'):\n",
        "        x_mins.append(tag.text)\n",
        "\n",
        "    x_maxs = []\n",
        "    for tag in root.findall('object/bndbox/xmax'):\n",
        "        x_maxs.append(tag.text)\n",
        "\n",
        "    y_mins = []\n",
        "    for tag in root.findall('object/bndbox/ymin'):\n",
        "        y_mins.append(tag.text)\n",
        "\n",
        "    y_maxs = []\n",
        "    for tag in root.findall('object/bndbox/ymax'):\n",
        "        y_maxs.append(tag.text)\n",
        "\n",
        "    return {\"filename\": xml_path,\n",
        "            \"image_width\": int(root.find(\"./size/width\").text),\n",
        "            \"image_height\": int(root.find(\"./size/height\").text),\n",
        "            \"image_channels\": int(root.find(\"./size/depth\").text),\n",
        "            \"label\": names,\n",
        "            \"x1\": x_mins,\n",
        "            \"y1\": y_mins,\n",
        "            \"x2\": x_maxs,\n",
        "            \"y2\": y_maxs}"
      ],
      "metadata": {
        "id": "CPPWER-1UPz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert human readable str label to int.\n",
        "label_dict = {\"mandarin\": 1, \"apple\" : 2, \"banana\" : 3, \"pepper\" : 4, \"cucumber\" : 5, \"carrot\" : 6}\n",
        "# Convert label int to human readable str.\n",
        "reverse_label_dict = {1: \"mandarin\", 2: \"apple\", 3: \"banana\", 4: \"pepper\", 5 : \"cucumber\", 6: \"carrot\"}"
      ],
      "metadata": {
        "id": "MOehvqVLUT3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mkpbZvjdUij1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xml_path  =   \"/content/train_xml/\"+ \"photo_10_2023-12-20_14-14-22\" + \".xml\"\n",
        "my_xml_to_dict(xml_path)"
      ],
      "metadata": {
        "id": "j_LMiLjvUVzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_show_with_box(im_name, dir_path, xml_path):\n",
        "    xml_path  =   xml_path+ im_name + \".xml\"\n",
        "    path_to_img = dir_path+ im_name + \".jpg\"\n",
        "    img = cv2.imread(path_to_img)\n",
        "    for i in range(len(my_xml_to_dict(xml_path)['x1'])):\n",
        "        x1 = int(my_xml_to_dict(xml_path)['x1'][i])\n",
        "        x2 = int(my_xml_to_dict(xml_path)['x2'][i])\n",
        "        y1 = int(my_xml_to_dict(xml_path)['y1'][i])\n",
        "        y2 = int(my_xml_to_dict(xml_path)['y2'][i])\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
        "        print(my_xml_to_dict(xml_path)['label'][i],\" :\", x1, x2, y1, y2)\n",
        "    #cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
        "    cv2_imshow(img)\n",
        "my_show_with_box(\"photo_10_2023-12-20_14-14-22\",  \"/content/train/\",\"/content/train_xml/\")"
      ],
      "metadata": {
        "id": "Xa2-AEvUUfB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def labelling(path_data, path_xml):\n",
        "    label_list = []\n",
        "    for i in range(len(sorted(os.listdir(path_data)))):\n",
        "        xml_path  =   path_xml+ sorted(os.listdir(path_xml))[i]\n",
        "        labels_name_list=my_xml_to_dict(xml_path)['label']\n",
        "        labels_fig_list = list()\n",
        "        for i in range(len(labels_name_list)):\n",
        "            labels_fig_list.append(int(label_dict[labels_name_list[i]]))\n",
        "        label_list.append(labels_fig_list)\n",
        "    all_boxes = list()\n",
        "    for i in range(len(sorted(os.listdir(path_data)))):\n",
        "        xml_path  =   path_xml+ sorted(os.listdir(path_xml))[i]\n",
        "        x1 = my_xml_to_dict(xml_path)['x1']\n",
        "        x2 = my_xml_to_dict(xml_path)['x2']\n",
        "        y1 = my_xml_to_dict(xml_path)['y1']\n",
        "        y2 = my_xml_to_dict(xml_path)['y2']\n",
        "        boxes = list()\n",
        "        for i in range(len(x1)):\n",
        "            boxes.append([int(x1[i]), int(y1[i]), int(x2[i]), int(y2[i])])\n",
        "        all_boxes.append(boxes)\n",
        "    d = {'filename': sorted(os.listdir(path_data)), 'class': label_list, 'bbox': all_boxes}\n",
        "    return pd.DataFrame(data=d)"
      ],
      "metadata": {
        "id": "I-XcZE_igQBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm  /content/train/aug*"
      ],
      "metadata": {
        "id": "WtL4-srljbER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = labelling(\"/content/train/\", \"/content/train_xml/\")"
      ],
      "metadata": {
        "id": "_bLzXrXdgpG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "id": "HJbiqFQSWOsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Augmentations"
      ],
      "metadata": {
        "id": "UsJFKhykWSht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "import cv2\n",
        "import copy\n",
        "count=0\n",
        "\n",
        "transform_rot90 = A.Compose([A.augmentations.geometric.transforms.Affine(rotate=90)], bbox_params=A.BboxParams(format='pascal_voc'))\n",
        "transform_rot180 = A.Compose([A.augmentations.geometric.transforms.Affine(rotate=180)], bbox_params=A.BboxParams(format='pascal_voc'))\n",
        "transform_random_bright = A.Compose([A.RandomBrightnessContrast(p=1)], bbox_params=A.BboxParams(format='pascal_voc'))\n",
        "transform_horizontal_flip = A.Compose([A.HorizontalFlip(p=1)], bbox_params=A.BboxParams(format='pascal_voc'))\n",
        "\n",
        "for num_sample in range(len(df_train)):\n",
        "#for num_sample in range(2):\n",
        "    trans_im_arr= list()\n",
        "    trans_box_arr= list()\n",
        "\n",
        "    #im_name = \"IMG_20230918_130424\"\n",
        "\n",
        "    a = list(df_train['filename'][[num_sample]])\n",
        "    im_name = a[0]\n",
        "\n",
        "    path_to_img = \"/content/train/\"+ im_name\n",
        "    image = cv2.imread(path_to_img)\n",
        "\n",
        "    a = df_train['bbox'][[num_sample]]\n",
        "    a = list(a)\n",
        "    b = copy.deepcopy(a)\n",
        "    #print(a[0])\n",
        "    #b[0].append('sdf')\n",
        "    box = b[0]\n",
        "    #print(len(box))\n",
        "    for i in range(len(box)):\n",
        "        box[i].append(\"dog\")\n",
        "    #print(box)\n",
        "    #box=[[149, 888, 836, 1563, 'dog']]\n",
        "    transformed1 = transform_rot90(image=image, bboxes=box)\n",
        "    transformed_image1 = transformed1['image']\n",
        "    transformed_bboxes1 = transformed1['bboxes']\n",
        "    trans_im_arr.append(transformed_image1)\n",
        "    trans_box_arr.append(transformed_bboxes1)\n",
        "\n",
        "    transformed2 = transform_rot180(image=image, bboxes=box)\n",
        "    transformed_image2 = transformed2['image']\n",
        "    transformed_bboxes2 = transformed2['bboxes']\n",
        "    trans_im_arr.append(transformed_image2)\n",
        "    trans_box_arr.append(transformed_bboxes2)\n",
        "\n",
        "    transformed3 = transform_horizontal_flip(image=image, bboxes=box)\n",
        "    transformed_image3 = transformed3['image']\n",
        "    transformed_bboxes3 = transformed3['bboxes']\n",
        "    trans_im_arr.append(transformed_image3)\n",
        "    trans_box_arr.append(transformed_bboxes3)\n",
        "\n",
        "    transformed4 = transform_horizontal_flip(image=transformed_image1, bboxes=transformed_bboxes1)\n",
        "    transformed_image4 = transformed4['image']\n",
        "    transformed_bboxes4 = transformed4['bboxes']\n",
        "    trans_im_arr.append(transformed_image4)\n",
        "    trans_box_arr.append(transformed_bboxes4)\n",
        "\n",
        "    transformed5 = transform_horizontal_flip(image=transformed_image2, bboxes=transformed_bboxes2)\n",
        "    transformed_image5 = transformed5['image']\n",
        "    transformed_bboxes5 = transformed5['bboxes']\n",
        "    trans_im_arr.append(transformed_image5)\n",
        "    trans_box_arr.append(transformed_bboxes5)\n",
        "\n",
        "\n",
        "    transformed6 = transform_random_bright(image=image, bboxes=box)\n",
        "    transformed_image6 = transformed6['image']\n",
        "    transformed_bboxes6 = transformed6['bboxes']\n",
        "    trans_im_arr.append(transformed_image6)\n",
        "    trans_box_arr.append(transformed_bboxes6)\n",
        "\n",
        "    for i in range(5):\n",
        "        transformed = transform_random_bright(image=trans_im_arr[i], bboxes=trans_box_arr[i])\n",
        "        transformed_image = transformed['image']\n",
        "        transformed_bboxes = transformed['bboxes']\n",
        "        trans_im_arr.append(transformed_image)\n",
        "        trans_box_arr.append(transformed_bboxes)\n",
        "\n",
        "    for i in range(len(trans_im_arr)): # цикл по 11 ауг картинкам\n",
        "        #print(i)\n",
        "        count+=1\n",
        "        new_box = list()\n",
        "        for j in range(len(trans_box_arr[i])): #цикл по рамкам\n",
        "            x1 = int(trans_box_arr[i][j][0])\n",
        "            x2 = int(trans_box_arr[i][j][2])\n",
        "            y1 = int(trans_box_arr[i][j][1])\n",
        "            y2 = int(trans_box_arr[i][j][3])\n",
        "            #cv2.rectangle(trans_im_arr[i], (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
        "            new_box.append(list(trans_box_arr[i][j][:4]))\n",
        "        #cv2_imshow(trans_im_arr[i])\n",
        "        cv2.imwrite(\"/content/train/aug\"+str(count)+\".jpg\", trans_im_arr[i]) # Save aug image as JPG file\n",
        "        f_name = \"aug\"+str(count)+\".jpg\"\n",
        "        new_row = {'filename':f_name, 'class':list(df_train['class'][[num_sample]])[0], 'bbox':new_box}\n",
        "        df_train = df_train.append(new_row, ignore_index=True)"
      ],
      "metadata": {
        "id": "AopQW_wTVYy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "id": "bbQiCvXWewiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets show our augmented data"
      ],
      "metadata": {
        "id": "b6AyqBrbZg7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_show_with_box_for_aug_df(num):\n",
        "    im_name = list(df_train['filename'][[num]])[0]\n",
        "    path_to_img = \"/content/train/\"+ im_name\n",
        "    print(path_to_img)\n",
        "    img = cv2.imread(path_to_img)\n",
        "    for i in range(len(list(df_train['bbox'][[num]])[0])):\n",
        "        x1 = int(list(df_train['bbox'][[num]])[0][i][0])\n",
        "        x2 = int(list(df_train['bbox'][[num]])[0][i][2])\n",
        "        y1 = int(list(df_train['bbox'][[num]])[0][i][1])\n",
        "        y2 = int(list(df_train['bbox'][[num]])[0][i][3])\n",
        "        print(x1,x2,y1,y2)\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
        "        #print(my_xml_to_dict(xml_path)['label'][i],\" :\", x1, x2, y1, y2)\n",
        "    # cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
        "    cv2_imshow(img)\n",
        "my_show_with_box_for_aug_df(1006)\n",
        "#my_show_with_box(\"aug3090\",  \"/content/train/aug\",\"/content/train_xml/\")\n"
      ],
      "metadata": {
        "id": "pJtDqTj8ZmEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val = labelling(\"/content/test/\", \"/content/test_xml/\")"
      ],
      "metadata": {
        "id": "GvT6VdOBhi8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val"
      ],
      "metadata": {
        "id": "v_YjUkq3U32f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_img_with_box(df_index, dir_path, scale_percent=20):\n",
        "    path_to_img = os.path.join(dir_path, df_train.loc[df_index, 'filename'])\n",
        "    print(path_to_img)\n",
        "    img = cv2.imread(path_to_img)\n",
        "    boxes =  df_train.loc[df_index, 'bbox']\n",
        "    for box in boxes:\n",
        "        cv2.rectangle(img,\n",
        "            (int(box[0]), int(box[1])),\n",
        "            (int(box[2]), int(box[3])),\n",
        "            (255, 0, 0), 5)\n",
        "    width = int(img.shape[1] * scale_percent / 100)\n",
        "    height = int(img.shape[0] * scale_percent / 100)\n",
        "    dim = (width, height)\n",
        "    img = cv2.resize(img, dim)\n",
        "    cv2_imshow(img)\n",
        "\n",
        "draw_img_with_box(10, \"/content/train\" )"
      ],
      "metadata": {
        "id": "F-z1h-h8VcGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Lets create custom dataset class"
      ],
      "metadata": {
        "id": "lFVrzZ_etayA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, dataframe, img_path):\n",
        "\n",
        "        self.df = dataframe\n",
        "        self.img_path = img_path\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name = self.df.loc[index,'filename']\n",
        "        boxes = torch.Tensor(self.df.loc[index, 'bbox']).to(torch.float)\n",
        "        labels = torch.Tensor(self.df.loc[index, 'class']).to(torch.int64)\n",
        "        area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 0])\n",
        "        iscrowd = torch.zeros(labels.shape[0], dtype=torch.int64)\n",
        "\n",
        "        target = {}\n",
        "        target['boxes'] = boxes\n",
        "        target['labels'] = labels\n",
        "\n",
        "        img = cv2.imread(os.path.join(self.img_path, img_name))/255.\n",
        "        img = torch.from_numpy(img).permute(2, 0, 1).to(torch.float)\n",
        "        return img, target"
      ],
      "metadata": {
        "id": "_ZtO2PiWVexG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Model creation"
      ],
      "metadata": {
        "id": "Hnnw9WistfOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(num_classes, pretrained=False):\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=pretrained)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model"
      ],
      "metadata": {
        "id": "R_1T7A7UVhKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ],
      "metadata": {
        "id": "8b3thypMVilV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = create_model(num_classes=7, pretrained=False).to(device)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.0005)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "\n",
        "train_dataset = MyDataset(df_train, '/content/train')\n",
        "val_dataset = MyDataset(df_val, '/content/test')\n",
        "\n",
        "train_data_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=3,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_data_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=3,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ],
      "metadata": {
        "id": "HFIG_pKdVkHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Lets train our Faster-RCNN"
      ],
      "metadata": {
        "id": "CYEEHcECtjPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dataloader):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for i, data in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        images, targets = data[0], data[1]\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        loss_dict = model(images, targets)\n",
        "        loss = sum(loss for loss in loss_dict.values())\n",
        "        running_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if i % 50 == 0:\n",
        "            print(f\"\\tИтерация #{i} loss: {loss}\")\n",
        "    train_loss = running_loss/len(train_dataloader.dataset)\n",
        "    return train_loss\n",
        "\n",
        "def val(val_dataloader):\n",
        "    running_loss = 0\n",
        "    for data in val_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        images, targets = data[0], data[1]\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        with torch.no_grad():\n",
        "            loss_dict = model(images, targets)\n",
        "        loss_dict = model(images, targets)\n",
        "        loss = sum(loss for loss in loss_dict.values())\n",
        "        running_loss += loss.item()\n",
        "    val_loss = running_loss/len(val_dataloader.dataset)\n",
        "    return val_loss"
      ],
      "metadata": {
        "id": "aHOC_nCBVnl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "try:\n",
        "    for epoch in range(7):\n",
        "        start = time.time()\n",
        "        train_loss = train(train_data_loader)\n",
        "        val_loss = val(val_data_loader)\n",
        "        scheduler.step()\n",
        "        print(f\"Эпоха #{epoch} train_loss: {train_loss}, val_loss: {val_loss}\")\n",
        "        end = time.time()\n",
        "        print(f\"Потрачено {round((end - start) / 60, 1)} минут на {epoch} эпоху\")\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "except KeyboardInterrupt:\n",
        "    print('Прервано пользователем')"
      ],
      "metadata": {
        "id": "4KrlMyMMVr8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7) Loss vizualization"
      ],
      "metadata": {
        "id": "3I7cOaWNtrjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax  = plt.subplots()\n",
        "ax.plot(train_losses, label='Train')\n",
        "ax.plot(val_losses, label='Val')\n",
        "ax.set(xlabel='Epoch', ylabel='Loss')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "oj2J18TSVwCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8) Inference"
      ],
      "metadata": {
        "id": "Mmj-RpvH0Pzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_index = 3\n",
        "model.eval()\n",
        "img = cv2.imread(os.path.join('/content/test', df_val.loc[df_index, 'filename']))\n",
        "img_ = img / 255.\n",
        "img_ = torch.from_numpy(img_).permute(2, 0, 1).unsqueeze(0).to(torch.float).to(device)\n",
        "predict = model(img_)"
      ],
      "metadata": {
        "id": "yQJ0pVGzwtLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict"
      ],
      "metadata": {
        "id": "JGlL5a8rwv5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_predict(df_index, iou_threshold=0.1, threshold=0.8, scale_percent=25):\n",
        "    model.eval()\n",
        "    img = cv2.imread(os.path.join('/content/test', df_val.loc[df_index, 'filename']))\n",
        "    print(df_val.loc[df_index, 'filename'])\n",
        "    img_ = img / 255.\n",
        "    img_ = torch.from_numpy(img_).permute(2, 0, 1).unsqueeze(0).to(torch.float).to(device)\n",
        "    predict = model(img_)\n",
        "    #print(predict)\n",
        "    #int(predict[0]['labels'][0])\n",
        "    #label_dict = {\"fruit drink\": 1, \"cabbage salad\" : 2, \"soup\" : 3}\n",
        "    ind = nms(predict[0]['boxes'], predict[0]['scores'], iou_threshold).detach().cpu().numpy()\n",
        "    for i, box in enumerate(predict[0]['boxes'][ind]):\n",
        "        #print(i)\n",
        "        color = (0,255,0)\n",
        "        if predict[0]['scores'][i] > threshold:\n",
        "            if int(predict[0]['labels'][i]) == 1: #fruit drink\n",
        "                color = (176,31,186)\n",
        "            if int(predict[0]['labels'][i]) == 2: #cabbcage salad\n",
        "                color = (0,255,0)\n",
        "            if int(predict[0]['labels'][i]) == 3: #mushrooms soup\n",
        "                color = (47,77,26)\n",
        "\n",
        "            cv2.rectangle(img,\n",
        "                    (int(box[0]), int(box[1])),\n",
        "                    (int(box[2]), int(box[3])),\n",
        "                    color, 5)\n",
        "            font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
        "            bottomLeftCornerOfText = (int(box[0]), int(box[1]))\n",
        "            fontScale              = 5\n",
        "            fontColor              = (255,255,255)\n",
        "            thickness              = 10\n",
        "            lineType               = 2\n",
        "            cv2.putText(img, reverse_label_dict[int(predict[0]['labels'][i])], bottomLeftCornerOfText, font, fontScale, fontColor, thickness, lineType)\n",
        "\n",
        "\n",
        "    width = int(img.shape[1] * scale_percent / 100)\n",
        "    height = int(img.shape[0] * scale_percent / 100)\n",
        "    dim = (width, height)\n",
        "    img = cv2.resize(img, dim)\n",
        "    cv2_imshow(img)\n",
        "draw_predict(3, 0.1)\n",
        "#bill_calculate(18, 0.1)"
      ],
      "metadata": {
        "id": "Mt3KhS6XWDCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'fasterrcnn_resnet50_fpn_5ka.pth')"
      ],
      "metadata": {
        "id": "cPFsXyQrhMvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/fasterrcnn_resnet50_fpn_5ka.pth\" /content/drive/MyDrive/Data/CV_proj"
      ],
      "metadata": {
        "id": "L2RCoQ70amRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9) Accuraccy"
      ],
      "metadata": {
        "id": "7aJGQPLiwHXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def read_xml(xml_path):\n",
        "    # Decode the .xml file\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "    # Return the image size, object label and bounding box\n",
        "    # coordinates together with the filename as a dict.\n",
        "    names = []\n",
        "\n",
        "    for tag in root.findall('object/name'):\n",
        "        names.append(tag.text)\n",
        "\n",
        "    x_mins = []\n",
        "    for tag in root.findall('object/bndbox/xmin'):\n",
        "        x_mins.append(tag.text)\n",
        "\n",
        "    x_maxs = []\n",
        "    for tag in root.findall('object/bndbox/xmax'):\n",
        "        x_maxs.append(tag.text)\n",
        "\n",
        "    y_mins = []\n",
        "    for tag in root.findall('object/bndbox/ymin'):\n",
        "        y_mins.append(tag.text)\n",
        "\n",
        "    y_maxs = []\n",
        "    for tag in root.findall('object/bndbox/ymax'):\n",
        "        y_maxs.append(tag.text)\n",
        "\n",
        "    boxes = []\n",
        "    for i in range(len(x_mins)):\n",
        "        boxes.append([int(x_mins[i]), int(y_mins[i]), int(x_maxs[i]), int(y_maxs[i])])\n",
        "\n",
        "    return {\"filename\": xml_path,\n",
        "            \"image_width\": int(root.find(\"./size/width\").text),\n",
        "            \"image_height\": int(root.find(\"./size/height\").text),\n",
        "            \"image_channels\": int(root.find(\"./size/depth\").text),\n",
        "            \"label\": names,\n",
        "            \"box\": boxes,\n",
        "            \"x1\": x_mins,\n",
        "            \"y1\": y_mins,\n",
        "            \"x2\": x_maxs,\n",
        "            \"y2\": y_maxs}\n"
      ],
      "metadata": {
        "id": "I_d2dXhVxTE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_iou(ground_truth, pred):\n",
        "    # coordinates of the area of intersection.\n",
        "    ix1 = np.maximum(ground_truth[0], pred[0])\n",
        "    iy1 = np.maximum(ground_truth[1], pred[1])\n",
        "    ix2 = np.minimum(ground_truth[2], pred[2])\n",
        "    iy2 = np.minimum(ground_truth[3], pred[3])\n",
        "\n",
        "    # Intersection height and width.\n",
        "    i_height = np.maximum(iy2 - iy1 + 1, np.array(0.))\n",
        "    i_width = np.maximum(ix2 - ix1 + 1, np.array(0.))\n",
        "\n",
        "    area_of_intersection = i_height * i_width\n",
        "\n",
        "    # Ground Truth dimensions.\n",
        "    gt_height = ground_truth[3] - ground_truth[1] + 1\n",
        "    gt_width = ground_truth[2] - ground_truth[0] + 1\n",
        "\n",
        "    # Prediction dimensions.\n",
        "    pd_height = pred[3] - pred[1] + 1\n",
        "    pd_width = pred[2] - pred[0] + 1\n",
        "\n",
        "    area_of_union = gt_height * gt_width + pd_height * pd_width - area_of_intersection\n",
        "\n",
        "    iou = area_of_intersection / area_of_union\n",
        "\n",
        "    return iou\n",
        "\n",
        "import torch\n",
        "from torch import tensor\n",
        "from torchvision import ops\n",
        "\n",
        "ops.box_iou(tensor([[72, 373, 708, 839]]), tensor([[80, 300, 710, 800]]))"
      ],
      "metadata": {
        "id": "HxX8-MfRwTKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_scores(img_xml, predict, threshold=0.8):\n",
        "    results = []\n",
        "    for i, score in enumerate(predict['scores']):\n",
        "        if score > threshold:\n",
        "            label_hat = predict['labels'][i]\n",
        "            box_hat = predict['boxes'][i]\n",
        "\n",
        "            scores = []\n",
        "            for j, label in enumerate(img_xml['label']):\n",
        "                if label_dict[label] == label_hat:\n",
        "                    scores.append(get_iou(img_xml['box'][j], box_hat.detach().numpy()))\n",
        "\n",
        "            iou = float(max(scores, default=0))\n",
        "            results.append( (iou > 0.5) * 1 )\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "AztarWTbwW66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model loading\n",
        "model = create_model(num_classes=7, pretrained=False).to(device)\n",
        "state_dict = torch.load('/content/drive/MyDrive/Data/CV_proj/fasterrcnn_resnet50_fpn_5ka.pth', map_location=torch.device('cpu'))\n",
        "model.load_state_dict(state_dict)\n"
      ],
      "metadata": {
        "id": "Hx2OpLX-wavT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\"mandarin\": 1, \"apple\" : 2, \"banana\" : 3, \"pepper\" : 4, \"cucumber\" : 5, \"carrot\" : 6}\n",
        "\n",
        "img_name = \"photo_2023-12-18_12-43-15.jpg\"\n",
        "\n",
        "predict = {'boxes': tensor([[649.7993, 160.8598, 977.5370, 490.6462],\n",
        "          [636.0603, 521.2333, 913.5746, 847.4760],\n",
        "          [644.7803, 161.2805, 972.5023, 482.9593],\n",
        "          [632.1509, 519.2692, 894.2546, 847.7626]]),\n",
        "  'labels': tensor([2, 2, 4, 4]),\n",
        "  'scores': tensor([0.9737, 0.9708, 0.0596, 0.0542])\n",
        "}\n",
        "\n",
        "xml_path  = f\"/content/test_xml/{img_name.split('.jpg')[0]}.xml\"\n",
        "img_xml = read_xml(xml_path)\n",
        "\n",
        "calc_scores(img_xml, predict)"
      ],
      "metadata": {
        "id": "czjVLjAiweKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c=0\n",
        "summ = 0.\n",
        "all = 0\n",
        "for i in df_val['filename']:\n",
        "    # if c == 12:\n",
        "    #     break\n",
        "    c+=1\n",
        "    model.eval()\n",
        "    img_name = i\n",
        "    img = cv2.imread(os.path.join('/content/test', img_name))\n",
        "    img_ = img / 255.\n",
        "    img_ = torch.from_numpy(img_).permute(2, 0, 1).unsqueeze(0).to(torch.float).to(device)\n",
        "    predict = model(img_)[0]\n",
        "    #print(predict)\n",
        "    xml_path  = f\"/content/test_xml/{img_name.split('.jpg')[0]}.xml\"\n",
        "    img_xml = read_xml(xml_path)\n",
        "    summ += np.sum(calc_scores(img_xml, predict))\n",
        "    all += len(calc_scores(img_xml, predict))\n",
        "    acc = summ/all\n",
        "    print(\"№\",c,\" -- \", \"calculated score: \", calc_scores(img_xml, predict), \"---\",\"cumulated accuracy:\", summ/all)\n",
        "    if np.sum(calc_scores(img_xml, predict)) != len(calc_scores(img_xml, predict)):\n",
        "        print(\"Not exact label: \",img_name)\n",
        "\n"
      ],
      "metadata": {
        "id": "FJmlcjaFeSvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets see pictures with incorrect labels:"
      ],
      "metadata": {
        "id": "sDMwd8Ypu_RE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "draw_predict(7, 0.1)"
      ],
      "metadata": {
        "id": "MxuVfG9_vUmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4iAC4zrrB9si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YUELY50MB93F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_predict(16, 0.1)"
      ],
      "metadata": {
        "id": "vKGgRNsQB4hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_predict(17, 0.1)"
      ],
      "metadata": {
        "id": "qcKjruEsB5VX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_predict(21, 0.1)"
      ],
      "metadata": {
        "id": "qyB_lrdTCMWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_predict(22, 0.1)"
      ],
      "metadata": {
        "id": "Kr6zwyzZCNHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_predict(7, 0.1)"
      ],
      "metadata": {
        "id": "tu9MdRx2DDxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KT8P9ZIADZMe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}